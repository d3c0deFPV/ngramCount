{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make output bigger for jupyter notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 60em; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import pycurl\n",
    "import certifi\n",
    "import re\n",
    "from io import BytesIO \n",
    "import nltk, re, string, collections\n",
    "from nltk.util import ngrams\n",
    "\n",
    "\n",
    "#Options\n",
    "dataURL = 'https://www.reddit.com/r/space/.json?count=250'\n",
    "killCase =            1      #Make everything lowercase\n",
    "parse =               1      #Basic parsing using parseRegex variable\n",
    "replacebadRegex =     0      #Replace pattern in badRegex\n",
    "replacebadChars =     1      #Replace characters in badChars\n",
    "onlybasicChars =      0      #Only alphanumeric and spaces\n",
    "splitbychar =         0      #Split by character (default is space)\n",
    "ngramMin =            2      #Smallest ngram to look for\n",
    "ngramMax =            20     #Largest ngram to look for\n",
    "minngramCount =       2      #Minimum number of times an ngram must be repeated\n",
    "ngramRedundant =      1      #Show non-unqiue ngrams inside of other larger ones\n",
    "mostcommonMax =     100      #How many ngrams max to return from most_common()\n",
    "responsesizeMax = 50000      #Largest response size to show\n",
    "ignoreSSLwarn =       0      #Don't check SSL certificates for curl\n",
    "showresponses =       0      #Show curl response and data\n",
    "\n",
    "\n",
    "#Regex matches\n",
    "badChars = [';', ':', '!', \"*\", \"<\", \">\", \"-\", \"\\\"\", \"=\"] \n",
    "badRegex = re.compile(r\"<[^>]*>\")\n",
    "parseRegex = re.compile(r'\"title\": \"(.*?)\"', flags=re.I|re.M) #reddit titles\n",
    "#badRegex = re.compile(r'wiki')\n",
    "#badRegex = re.compile(r\".*?<body>(.*?)</body>\")\n",
    "alphanumspaceRegex = re.compile(r\"[^a-zA-Z0-9\\s]\")\n",
    "\n",
    "#Curl page for data\n",
    "b_obj = BytesIO() \n",
    "crl = pycurl.Curl() \n",
    "crl.setopt(crl.URL, dataURL)\n",
    "if ignoreSSLwarn == 1:\n",
    "    crl.setopt(pycurl.SSL_VERIFYPEER, 0) #trust invalid SSL\n",
    "    crl.setopt(pycurl.SSL_VERIFYHOST, 0) #trust invalid SSL\n",
    "crl.setopt(crl.WRITEDATA, b_obj)\n",
    "crl.setopt(pycurl.USERAGENT, \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0\")\n",
    "crl.setopt(pycurl.CAINFO, certifi.where())\n",
    "crl.perform() \n",
    "crl.close()\n",
    "get_body = b_obj.getvalue()\n",
    "curlResponse = str(get_body.decode('utf8'))\n",
    "\n",
    "#Print responses if enabled\n",
    "if showresponses == 1:\n",
    "    curlResponseSize = sys.getsizeof(curlResponse)\n",
    "    #Don't print huge amounts of data\n",
    "    if (curlResponseSize < responsesizeMax):\n",
    "        print(curlResponse)\n",
    "    else:\n",
    "        print(\"Curl response too big for display, \" + str(curlResponseSize) + \" bytes, max is \" + str(responsesizeMax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching regex: \"title\": \"(.*?)\"\n",
      "Before size:\t112.19\tKB\n",
      "After size:\t2.7\tKB\n",
      "\n",
      "Removing the following chars: [';', ':', '!', '*', '<', '>', '-', '\"', '=']\n",
      "Before size:\t2.7\tKB\n",
      "After size:\t2.69\tKB\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Common ngrams, longest to shortest: \n",
      "\n",
      "3\tblack hole\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "ngram search time:\t 0.010011672973632812 seconds\n",
      "Total processing time:\t 0.013009309768676758 seconds\n",
      "\n",
      "Source:\thttps://www.reddit.com/r/space/.json?count=250\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data = curlResponse\n",
    "combinedngram = ''\n",
    "\n",
    "def getdataSizeKB(inputdata):\n",
    "    sizeKB = sys.getsizeof(inputdata) / 1024\n",
    "    return str(str(round(sizeKB, 2)) + \"\\tKB\")\n",
    "\n",
    "if killCase == 1:\n",
    "    data = data.lower()\n",
    "\n",
    "if parse == 1:\n",
    "    #print(data)\n",
    "    print(\"Matching regex: \" + str(parseRegex.pattern))\n",
    "    print(\"Before size:\\t\" + getdataSizeKB(data))\n",
    "    parsedfindall = sorted(set(re.findall(parseRegex, data))) #sort/uniq to remove repeated found patterns of same text\n",
    "    parsedData = ''\n",
    "    for item in parsedfindall:\n",
    "        parsedData = parsedData + str(item) + \"\\n\"\n",
    "    data = parsedData\n",
    "    print(\"After size:\\t\" + getdataSizeKB(data))\n",
    "\n",
    "if replacebadRegex == 1:\n",
    "    print(\"\\nRemoving data matching regex: \" + str(badRegex.pattern))\n",
    "    print(\"Before size:\\t\" + getdataSizeKB(data))\n",
    "    data = re.sub(badRegex, ' ', data) \n",
    "    print(\"After size:\\t\" + getdataSizeKB(data))\n",
    "\n",
    "if replacebadChars == 1:\n",
    "    print(\"\\nRemoving the following chars: \" + str(badChars))\n",
    "    print(\"Before size:\\t\" + getdataSizeKB(data))\n",
    "    for i in badChars : \n",
    "        data = data.replace(i, '') \n",
    "    print(\"After size:\\t\" + getdataSizeKB(data))\n",
    "\n",
    "if onlybasicChars == 1:\n",
    "    print(\"\\nRemoving non-alphanumeric except spaces: \" + str(alphanumspaceRegex.pattern))\n",
    "    print(\"Before size:\\t\" + getdataSizeKB(data))\n",
    "    \"\".join(i for i in data if ord(i)<128)\n",
    "    data = re.sub(alphanumspaceRegex, '', data)\n",
    "    print(\"After size:\\t\" + getdataSizeKB(data))\n",
    "\n",
    "#Single character splitting vs default of space\n",
    "if splitbychar == 1:\n",
    "    print(\"Splitting by character\")\n",
    "    def split(word): \n",
    "        return [char for char in word]  \n",
    "    tokenized = split(data)\n",
    "else: \n",
    "    tokenized = data.split()\n",
    "    #print(tokenized)\n",
    "    \n",
    "ngramstart = time.time()\n",
    "#iterate ngram length from ngramMin to ngramMax\n",
    "for i in range(ngramMax,(ngramMin - 1),-1):\n",
    "    #print('ngram length:' + str(i) + '\\n')\n",
    "    ngramResults = ngrams(tokenized, i)\n",
    "    ngramFreq = collections.Counter(ngramResults)\n",
    "    ngramCommon = ngramFreq.most_common(mostcommonMax)\n",
    "    #print(ngramCommon)\n",
    "    #Split results for text comparison\n",
    "    for list in ngramCommon:\n",
    "        ngramStr = ' '.join(str(character) for character in list[0])\n",
    "        ngramCount = list[1]\n",
    "        if ngramRedundant == 1:\n",
    "            if ngramCount > minngramCount:\n",
    "                combinedngram = combinedngram + str(ngramCount) + \"\\t\" + ngramStr + \"\\n\"\n",
    "        else:\n",
    "            #Only add if not found in larger match\n",
    "            if combinedngram.find(ngramStr) == -1 and ngramCount > minngramCount:\n",
    "                combinedngram = combinedngram + str(ngramCount) + \"\\t\" + ngramStr + \"\\n\"\n",
    "            \n",
    "\n",
    "print(\"\\n\" + (\"-\" * 75))\n",
    "print(\"\\nCommon ngrams, longest to shortest: \" + \"\\n\\n\" + combinedngram)\n",
    "print(\"-\" * 75)\n",
    "print(\"ngram search time:\\t\", time.time() - ngramstart, \"seconds\")\n",
    "print(\"Total processing time:\\t\", time.time() - start, \"seconds\")\n",
    "print(\"\\nSource:\\t\" + dataURL)\n",
    "print(\"-\" * 75)\n",
    "\n",
    "#Show response if enabled\n",
    "if showresponses == 1:\n",
    "    print(\"\\n\\nshowresponses = 1, displaying data...\")\n",
    "    curlResponseSize = sys.getsizeof(curlResponse)\n",
    "    dataSize = sys.getsizeof(data)\n",
    "    combinedngramSize = sys.getsizeof(combinedngram)\n",
    "    #print(combinedngramSize,dataSize,curlResponseSize)\n",
    "    #Don't print huge amounts of data\n",
    "    if (combinedngramSize < responsesizeMax):\n",
    "        print(\"combinedngram:\\n\\n\" + combinedngram)\n",
    "    else:\n",
    "        print(\"combinedngram larger than max response size in config - \" + str(combinedngramSize) + \" bytes, max is \" + str(responsesizeMax))\n",
    "    if (dataSize < responsesizeMax):\n",
    "        print(\"Data:\\n\\n\" + data)\n",
    "    else:\n",
    "        print(\"data larger than max response size in config - \" + str(dataSize) + \" bytes, max is \" + str(responsesizeMax))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
