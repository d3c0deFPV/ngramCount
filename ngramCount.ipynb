{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T05:01:15.680675Z",
     "start_time": "2020-06-06T05:01:15.672671Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.output_scroll { height: 60em; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Make output bigger for jupyter notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 60em; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T05:01:17.451043Z",
     "start_time": "2020-06-06T05:01:15.681674Z"
    },
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curl response too big for display, 186136 bytes, max is 10000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import pycurl\n",
    "import certifi\n",
    "import re\n",
    "from io import BytesIO\n",
    "import nltk, re, string, collections\n",
    "from nltk.util import ngrams\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "#Options\n",
    "dataURL = 'https://www.reddit.com/r/news+politics+worldnews/.json?count=250'   #URL used by curl to source data from body\n",
    "killCase = 1                                               #Make everything lowercase\n",
    "parse = 1                                                  #Basic parsing using parseRegex variable\n",
    "replacebadRegex = 1                                        #Replace pattern in badRegex\n",
    "replacebadChars = 1                                        #Replace characters in badChars\n",
    "onlybasicChars = 0                                         #Only alphanumeric and spaces\n",
    "splitbychar = 0                                            #Split by character (default is space)\n",
    "ngramMin = 1                                               #Smallest ngram to look for\n",
    "ngramMax = 20                                              #Largest ngram to look for\n",
    "minngramCount = 2                                          #Minimum number of times an ngram must be repeated\n",
    "ngramRedundant = 0                                         #Show non-unqiue ngrams inside of other larger ones\n",
    "mostcommonMax = 100                                        #How many ngrams max to return from most_common()\n",
    "responsesizeMax = 10000                                    #Largest response size to show\n",
    "ignoreSSLwarn = 0                                          #Don't check SSL certificates for curl\n",
    "showresponses = 1                                          #Show curl response and data\n",
    "\n",
    "#Regex matches\n",
    "badChars = [';', ':', '!', \"*\", \"<\", \">\", \"-\", \"\\\"\", \"=\"]\n",
    "parseRegex = re.compile(r'\"title\": \"(.*?)\"', flags=re.I | re.M)  #reddit titles\n",
    "badRegex = re.compile(r'\\\\u\\d+')\n",
    "#badRegex = re.compile(r\"<[^>]*>\") #HTML tags\n",
    "#badRegex = re.compile(r\".*?<body>(.*?)</body>\")\n",
    "alphanumspaceRegex = re.compile(r\"[^a-zA-Z0-9\\s]\")\n",
    "\n",
    "#Curl page for data\n",
    "b_obj = BytesIO()\n",
    "crl = pycurl.Curl()\n",
    "crl.setopt(crl.URL, dataURL)\n",
    "if ignoreSSLwarn == 1:\n",
    "    crl.setopt(pycurl.SSL_VERIFYPEER, 0)  #trust invalid SSL\n",
    "    crl.setopt(pycurl.SSL_VERIFYHOST, 0)  #trust invalid SSL\n",
    "crl.setopt(crl.WRITEDATA, b_obj)\n",
    "crl.setopt(\n",
    "    pycurl.USERAGENT,\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0\"\n",
    ")\n",
    "crl.setopt(pycurl.CAINFO, certifi.where())\n",
    "crl.perform()\n",
    "crl.close()\n",
    "get_body = b_obj.getvalue()\n",
    "curlResponse = str(get_body.decode('utf8'))\n",
    "\n",
    "\n",
    "\n",
    "#Print responses if enabled\n",
    "if showresponses == 1:\n",
    "    curlResponseSize = sys.getsizeof(curlResponse)\n",
    "    #Don't print huge amounts of data\n",
    "    if (curlResponseSize < responsesizeMax):\n",
    "        print(curlResponse)\n",
    "    else:\n",
    "        print(\"Curl response too big for display, \" + str(curlResponseSize) +\n",
    "              \" bytes, max is \" + str(responsesizeMax))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T05:01:17.718208Z",
     "start_time": "2020-06-06T05:01:17.452043Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching regex: \"title\": \"(.*?)\"\n",
      "Before size:\t181.77\tKB\n",
      "After size:\t2.24\tKB\n",
      "\n",
      "Removing data matching regex: \\\\u\\d+\n",
      "Before size:\t2.24\tKB\n",
      "After size:\t2.2\tKB\n",
      "\n",
      "Removing the following chars: [';', ':', '!', '*', '<', '>', '-', '\"', '=']\n",
      "Before size:\t2.2\tKB\n",
      "After size:\t2.19\tKB\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Common ngrams, longest to shortest: \n",
      "\n",
      "2\tpentagon orders remaining activeduty troops to leave\n",
      "2\tgeorge floyd's\n",
      "2\tin north\n",
      "8\tpolice\n",
      "6\tthe\n",
      "5\ttrump\n",
      "5\tof\n",
      "4\tit\n",
      "3\tat\n",
      "3\tduring\n",
      "3\twas\n",
      "3\tfor\n",
      "3\tofficers\n",
      "3\twe\n",
      "3\tpresident\n",
      "2\ttrudeau\n",
      "2\tantiracism\n",
      "2\tmay\n",
      "2\tthan\n",
      "2\tand\n",
      "2\this\n",
      "2\tvoted\n",
      "2\tused\n",
      "2\tnot\n",
      "2\ttrump's\n",
      "2\tbill\n",
      "2\tjust\n",
      "2\tout\n",
      "2\tman\n",
      "2\twashington\n",
      "2\tnfl\n",
      "2\tarea\n",
      "2\tprotest\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "ngram search time:\t 0.01100015640258789 seconds\n",
      "Total processing time:\t 0.014011383056640625 seconds\n",
      "\n",
      "Source:\thttps://www.reddit.com/r/news+politics+worldnews/.json?count=250\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "showresponses = 1, displaying data...\n",
      "combinedngram:\n",
      "\n",
      "2\tpentagon orders remaining activeduty troops to leave\n",
      "2\tgeorge floyd's\n",
      "2\tin north\n",
      "8\tpolice\n",
      "6\tthe\n",
      "5\ttrump\n",
      "5\tof\n",
      "4\tit\n",
      "3\tat\n",
      "3\tduring\n",
      "3\twas\n",
      "3\tfor\n",
      "3\tofficers\n",
      "3\twe\n",
      "3\tpresident\n",
      "2\ttrudeau\n",
      "2\tantiracism\n",
      "2\tmay\n",
      "2\tthan\n",
      "2\tand\n",
      "2\this\n",
      "2\tvoted\n",
      "2\tused\n",
      "2\tnot\n",
      "2\ttrump's\n",
      "2\tbill\n",
      "2\tjust\n",
      "2\tout\n",
      "2\tman\n",
      "2\twashington\n",
      "2\tnfl\n",
      "2\tarea\n",
      "2\tprotest\n",
      "\n",
      "Data:\n",
      "\n",
      "'breonna's law,' aimed at regulating noknock warrants in louisville, passes public safety committee\n",
      "'stand up to trump' canadian protesters shout to trudeau during antiracism rally\n",
      "a  misclassification error  made the may unemployment rate look better than it is. here s what happened.\n",
      "as they scream voter fraud, trump and his press secretary may have voted illegally | kayleigh mcenany was living in washington, but voted in florida. trump used an address he promised palm beach officials would not be a residence.\n",
      "biden says trump putting words in george floyd's mouth is 'despicable'\n",
      "california d.a.s call for ban on police union money and endorsements in prosecutorial elections\n",
      "canada pm trudeau joins antiracism march in ottawa\n",
      "congress must impeach trump's enabler in corruption, oppression, attorney general bill barr\n",
      "france announces it has killed the leader of al qaeda in north africa during an operation in mali\n",
      "fuji's distributor suspends sales of police bikes in north america\n",
      "how much does the american taxpayer pay to protect trump at his properties? wapo just sued to find out\n",
      "illinois  top legal officer wants to license cops, just like doctors, hairdressers\n",
      "kamala harris to trump 'keep george floyd's name out of your mouth'\n",
      "man wearing blm shirt to church gets assaulted by churchgoer in new zealand.\n",
      "mayor orders termination of 4 officers after black man died from police restraint in tacoma, washington\n",
      "nfl condems racism, admits  c we we re wrong d not to listen to nfl player protests\n",
      "pentagon orders remaining activeduty troops to leave dc area\n",
      "pentagon orders remaining activeduty troops to leave washington area\n",
      "philadelphia police inspector joseph bologna will face assault charges in the beating of a temple student at a protest\n",
      "police board president officers struck me 5 times with their batons during protest\n",
      "searching twitter for 'racist' shows you president donald trump's account\n",
      "the police are gaslighting us\n",
      "the president s inhumanity is deeper than we knew\n",
      "us park police it was a  cmistake d to say no tear gas was used in lafayette square\n",
      "warren, pressley introduce bill to make it a crime for police officers to deny medical care to people in custody\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data = curlResponse\n",
    "combinedngram = ''\n",
    "\n",
    "getdataSizeKB = lambda inputdata: str(\n",
    "    str(round(sys.getsizeof(inputdata) / 1024, 2)) + \"\\tKB\")\n",
    "\n",
    "if killCase == 1:\n",
    "    data = data.lower()\n",
    "\n",
    "if parse == 1:\n",
    "    #print(data)\n",
    "    print(\"Matching regex: \" + str(parseRegex.pattern))\n",
    "    print(\"Before size:\\t\" + getdataSizeKB(data))\n",
    "    parsedfindall = sorted(set(re.findall(\n",
    "        parseRegex,\n",
    "        data)))  #sort/uniq to remove repeated found patterns of same text\n",
    "    parsedData = ''\n",
    "    for item in parsedfindall:\n",
    "        parsedData = parsedData + str(item) + \"\\n\"\n",
    "    data = parsedData\n",
    "    print(\"After size:\\t\" + getdataSizeKB(data))\n",
    "\n",
    "if replacebadRegex == 1:\n",
    "    print(\"\\nRemoving data matching regex: \" + str(badRegex.pattern))\n",
    "    print(\"Before size:\\t\" + getdataSizeKB(data))\n",
    "    data = re.sub(badRegex, ' ', data)\n",
    "    print(\"After size:\\t\" + getdataSizeKB(data))\n",
    "\n",
    "if replacebadChars == 1:\n",
    "    print(\"\\nRemoving the following chars: \" + str(badChars))\n",
    "    print(\"Before size:\\t\" + getdataSizeKB(data))\n",
    "    for i in badChars:\n",
    "        data = data.replace(i, '')\n",
    "    print(\"After size:\\t\" + getdataSizeKB(data))\n",
    "\n",
    "if onlybasicChars == 1:\n",
    "    print(\"\\nRemoving non-alphanumeric except spaces: \" +\n",
    "          str(alphanumspaceRegex.pattern))\n",
    "    print(\"Before size:\\t\" + getdataSizeKB(data))\n",
    "    \"\".join(i for i in data if ord(i) < 128)\n",
    "    data = re.sub(alphanumspaceRegex, '', data)\n",
    "    print(\"After size:\\t\" + getdataSizeKB(data))\n",
    "\n",
    "#Single character splitting vs default of space\n",
    "if splitbychar == 1:\n",
    "    print(\"Splitting by character\")\n",
    "\n",
    "    def split(word):\n",
    "        return [char for char in word]\n",
    "\n",
    "    tokenized = split(data)\n",
    "else:\n",
    "    tokenized = data.split()\n",
    "    #print(tokenized)\n",
    "\n",
    "ngramstart = time.time()\n",
    "#iterate ngram length from ngramMin to ngramMax\n",
    "for i in range(ngramMax, (ngramMin - 1), -1):\n",
    "    #print('ngram length:' + str(i) + '\\n')\n",
    "    ngramResults = ngrams(tokenized, i)\n",
    "    ngramFreq = collections.Counter(ngramResults)\n",
    "    ngramCommon = ngramFreq.most_common(mostcommonMax)\n",
    "    #print(ngramCommon)\n",
    "    #Split results for text comparison\n",
    "    for list in ngramCommon:\n",
    "        ngramStr = ' '.join(str(character) for character in list[0])\n",
    "        ngramCount = list[1]\n",
    "        if ngramRedundant == 1:\n",
    "            if ngramCount >= minngramCount:\n",
    "                combinedngram = combinedngram + str(\n",
    "                    ngramCount) + \"\\t\" + ngramStr + \"\\n\"\n",
    "        else:\n",
    "            #Only add if not found in larger match\n",
    "            if combinedngram.find(\n",
    "                    ngramStr) == -1 and ngramCount >= minngramCount:\n",
    "                combinedngram = combinedngram + str(\n",
    "                    ngramCount) + \"\\t\" + ngramStr + \"\\n\"\n",
    "\n",
    "print(\"\\n\" + (\"-\" * 75))\n",
    "print(\"\\nCommon ngrams, longest to shortest: \" + \"\\n\\n\" + combinedngram)\n",
    "print(\"-\" * 75)\n",
    "print(\"ngram search time:\\t\", time.time() - ngramstart, \"seconds\")\n",
    "print(\"Total processing time:\\t\", time.time() - start, \"seconds\")\n",
    "print(\"\\nSource:\\t\" + dataURL)\n",
    "print(\"-\" * 75)\n",
    "\n",
    "#Show response if enabled\n",
    "if showresponses == 1:\n",
    "    print(\"\\n\\nshowresponses = 1, displaying data...\")\n",
    "    curlResponseSize = sys.getsizeof(curlResponse)\n",
    "    dataSize = sys.getsizeof(data)\n",
    "    combinedngramSize = sys.getsizeof(combinedngram)\n",
    "    #print(combinedngramSize,dataSize,curlResponseSize)\n",
    "    #Don't print huge amounts of data\n",
    "    if (combinedngramSize < responsesizeMax):\n",
    "        print(\"combinedngram:\\n\\n\" + combinedngram)\n",
    "    else:\n",
    "        print(\"combinedngram larger than max response size in config - \" +\n",
    "              str(combinedngramSize) + \" bytes, max is \" +\n",
    "              str(responsesizeMax))\n",
    "    if (dataSize < responsesizeMax):\n",
    "        print(\"Data:\\n\\n\" + data)\n",
    "    else:\n",
    "        print(\"data larger than max response size in config - \" +\n",
    "              str(dataSize) + \" bytes, max is \" + str(responsesizeMax))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "811px",
    "left": "908px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
